{
  "model": "distilgpt2",
  "dataset": "training/distilled/live_distill.jsonl",
  "output": "training/output_lora_distilgpt2",
  "lora": true,
  "epochs": 1,
  "elapsed_s": 4.147597074508667
}